aws:
  bucket_name: 'sul-sdr-aws-us-west-2-test' # override in prod

# rename to zip_endpoints
archive_endpoints:
  aws_s3_west_2:
    endpoint_node: 'us-west-2'
    storage_location: 'sul-sdr-aws-us-west-2-test'
    delivery_class: 'S3WestDeliveryJob'
  aws_s3_east_1:
    endpoint_node: 'us-east-1'
    storage_location: 'sul-sdr-aws-us-east-1-test'
    delivery_class: 'S3EastDeliveryJob'

# named storage roots are in the storage_root_map (see config/settings for examples).
# the storage_root_map contains lookups of storage roots per host.
# see sul-dlss/shared_configs for the storage_root_map of all hosts we deploy to.
endpoints:
  # the defaults used when seeding the endpoints that correspond to local storage roots
  storage_root_defaults:
    endpoint_node: 'localhost'

moab:
  # storage_trunk is the name of the directory under a storage_root which contains
  # the druid trees:  e.g. 'spec/fixtures/storage_root01/sdr2objects' will contain all the druid
  # trees for this configuration.  if there are multiple storage roots, each will have
  # the subdirectory specified by the same storage_trunk (e.g. 'storage_root1/storage_trunk',
  # 'storage_root2/storage_trunk', etc).
  storage_trunk: 'sdr2objects'
  path_method: druid_tree
  allow_content_subdirs: true

preservation_policies:
  default_policy_name: 'default'
  policy_definitions:
    default:
      archive_ttl: 604_800 # _ttl values are in seconds. 604,800 s == one week.
      fixity_ttl: 604_800

provlog:
  enable: false

storage_root_map: # empty here, override in #{RAILS_ENV}.yml
  default: {}

workflow_services_url: 'https://workflows.example.org/workflow/'
c2m_sql_limit: 1000

checksum_algos: ['md5'] # 'sha1' 'sha256'

zip_storage: '/tmp' # override in #{RAILS_ENV}.yml

resque_dashboard_hostnames: # tells the router where to mount the resque dashboard
  - 'worker-hostname-01.example.com'
  - 'worker-hostname-02.example.com'
