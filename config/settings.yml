dor_services:
  url: 'https://dor-services-app.example.edu'
  token: 'not-a-real-token'

# named storage roots are in the storage_root_map (see config/settings/xxx.yml for examples).
# the storage_root_map contains lookups of storage roots per host.
# see sul-dlss/shared_configs for the storage_root_map of all hosts we deploy to.

moab:
  # storage_trunk is the name of the directory under a storage_root which contains
  # the druid trees:  e.g. 'spec/fixtures/storage_root01/sdr2objects' will contain all the druid
  # trees for this configuration.  if there are multiple storage roots, each will have
  # the subdirectory specified by the same storage_trunk (e.g. 'storage_root1/storage_trunk',
  # 'storage_root2/storage_trunk', etc).
  storage_trunk: 'sdr2objects'
  path_method: druid_tree
  allow_content_subdirs: true

provlog:
  enable: false

storage_root_map: # empty here, override in #{RAILS_ENV}.yml
  default: {}

workflow_services_url: 'https://workflows.example.org/workflow/'

checksum_algos: ['md5'] # 'sha1' 'sha256'

zip_cache_expiry_time: '+10080' # this is UNIX `find` speak for "greater than seven days"
zip_storage: '/tmp' # override in #{RAILS_ENV}.yml

resque_dashboard_hostnames: # tells the router where to mount the resque dashboard
  - 'worker-hostname-01.example.com'
  - 'worker-hostname-02.example.com'

# When the backlog of unreplicated moabs is very large, e.g. when first spinning up
# the catalog, or when adding a new ZipEndpoint after the catalog has been running, we
# want to manually choose batches of moabs to replicate, so that we don't accidentally
# overrun the zip creation temp space.
# In normal steady state operation, this should be set to true, either here, or in the
# instance specific configs.
replication:
  audit_should_backfill: false

total_worker_count: 117 # for okcomputer endpoint

api_jwt:
  hmac_secret: 'my$ecretK3y'

# we expect/hope that this will not stay around forever.  see usage for further explanation.
hacks:
  update_catalog_sleep:
    base_time: 0.05    # the default values are artificially low to keep test suite fast -- should override to be many seconds in prod
    max_stagger: 0.01
