# named storage roots are in the storage_root_map (see config/settings/xxx.yml for examples).
# the storage_root_map contains lookups of storage roots per host.
# see sul-dlss/shared_configs for the storage_root_map of all hosts we deploy to.

moab:
  # storage_trunk is the name of the directory under a storage_root which contains
  # the druid trees:  e.g. 'spec/fixtures/storage_root01/sdr2objects' will contain all the druid
  # trees for this configuration.  if there are multiple storage roots, each will have
  # the subdirectory specified by the same storage_trunk (e.g. 'storage_root1/storage_trunk',
  # 'storage_root2/storage_trunk', etc).
  storage_trunk: 'sdr2objects'
  path_method: druid_tree
  allow_content_subdirs: true

preservation_policy:
  # the frequency with which the existence of the appropriate archive copies should be checked.
  archive_ttl: 7_776_000 # 90 days
  # the frequency with which the Moabs on storage should be checked for fixity.
  fixity_ttl: 7_776_000 # 90 days

provlog:
  enable: false

storage_root_map: # empty here, override in #{RAILS_ENV}.yml
  default: {}

workflow_services_url: 'https://workflows.example.org/workflow/'

checksum_algos: ['md5'] # 'sha1' 'sha256'

zip_cache_expiry_time: '+20160' # this is UNIX `find` speak for "greater than 14 days"
zip_storage: '/tmp' # override in #{RAILS_ENV}.yml

# When the backlog of unreplicated moabs is very large, e.g. when first spinning up
# the catalog, or when adding a new ZipEndpoint after the catalog has been running, we
# want to manually choose batches of moabs to replicate, so that we don't accidentally
# overrun the zip creation temp space.
# In normal steady state operation, this should be set to true, either here, or in the
# instance specific configs.
replication:
  audit_should_backfill: false

total_worker_count: 117 # for okcomputer endpoint
minimum_subfolder_count: 1 # for okcomputer pres-cat mount check, verifies the storage_trunk has at least this many subfolders
                           # NOTE: when null, no minimum check is performed, and this can be overriden per environment as needed
worker_hostnames: # used for OK computer checks
  - 'worker-hostname-01.example.com'
  - 'worker-hostname-02.example.com'

api_jwt:
  hmac_secret: 'my$ecretK3y'

filesystem_delay_seconds: 0.05 # the default value is artificially low to keep test suite fast

rabbitmq:
  hostname: localhost
  vhost: /
  username: guest
  password: guest

redis_url: redis://localhost:6379/
redis_timeout: 5 # seconds

honeybadger_checkins:
  moab_to_catalog: xyzzy
  catalog_to_moab: xyzzy
  checksum_validation: xyzzy
  audit_replication: xyzzy

slow_queries:
  enable: false
  threshold: 500

